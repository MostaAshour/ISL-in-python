{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Linear Regression\n",
    "By [**Mosta Ashour**](https://www.linkedin.com/in/mosta-ashour/)\n",
    "- **Chapter 3 from the book [An Introduction to Statistical Learning](https://www.statlearning.com/).**\n",
    "- **By Gareth James, Daniela Witten, Trevor Hastie and Rob Tibshirani.**\n",
    "- **Pages from $120$ to $121$**\n",
    "\n",
    "\n",
    "- **Exercises:**\n",
    " - **[1.](#1)**\n",
    " - **[2.](#2)**\n",
    " - **[3.](#3)**\n",
    " - **[4.](#4)**\n",
    " - **[5.](#5)**\n",
    " - **[6.](#6)**\n",
    " - **[7.](#7)**\n",
    " \n",
    "# <span style=\"font-family:cursive;color:#0071bb;\"> 3.7 Exercises </span>\n",
    "## <span style=\"font-family:cursive;color:#0071bb;\"> Conceptual </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### $1.$ Describe the null hypotheses to which the $\\text{p-values}$ given in Table 3.4 correspond. Explain what conclusions you can draw based on these p-values. Your explanation should be phrased in terms of <span style=\"font-family:cursive;color:red;\"> $sales, TV, radio,$ </span> and <span style=\"font-family:cursive;color:red;\"> $newspaper,$ </span> rather than in terms of the coefficients of the linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3_table3_4](img/3_table3_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The null hypothesis in this case are:**\n",
    " - That there is no relationship between amount spent on $TV, radio, newspaper$ advertising and $Sales$\n",
    "\n",
    "$$H_{0}^{(TV)}: \\beta_1 = 0$$\n",
    "$$H_{0}^{(radio)}: \\beta_2 = 0$$\n",
    "$$H_{0}^{(newspaper)}: \\beta_3 = 0$$\n",
    "\n",
    "- From the **p-values** above, it does appear that $TV$ and $radio$ have a significant impact on sales and not $newspaper$.\n",
    "\n",
    "- The **p-values** given in table 3.4 suggest that we **can reject** the null hypotheses for $TV$ and $newspaper$ and we **can't reject** the null hypothesis for $newspaper$. \n",
    "- It seems likely that there is a relationship between TV ads and Sales, and radio ads and sales and not $newspaper$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### $2.$ Carefully explain the differences between the $\\text{KNN}$ classifier and $\\text{KNN}$ regression methods.\n",
    "\n",
    "- **$\\text{KNN}$ classifier methods** \n",
    " - Attempts to predict the **class** to which the output variable belong by computing the local probability and determines a decision boundary `\"typically used for qualitative response, classification problems\"`.\n",
    "\n",
    "- **$\\text{KNN}$ regression methods** \n",
    " - Tries to predict the **value** of the output variable by using a local average `\"typically used for quantitative response, regression problems\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### $3.$ Suppose we have a data set with five predictors, $X_1 = GPA$, $X_2 = IQ$, $X_3 = Gender$ (1 for Female and 0 for Male), $X_4 = \\text{Interaction between GPA and IQ}$, and $X_5 = \\text{Interaction between GPA and Gender}$. The response is starting salary after graduation (in thousands of dollars). Suppose we use least squares to fit the model, and get $\\hat{β_0} = 50, \\hat{β_1} = 20 , \\hat{β_2} = 0.07 , \\hat{β_3} = 35 , \\hat{β_4} = 0.01 , \\hat{β_5} = −10$ .\n",
    "\n",
    "**$(a)$** Which answer is correct, and why?\n",
    "\n",
    "- $i.$ For a fixed value of IQ and GPA, males earn more on average than females.\n",
    "- $ii.$ For a fixed value of IQ and GPA, females earn more on average than males.\n",
    "- **$iii.$ For a fixed value of IQ and GPA, males earn more on average than females provided that the GPA is high enough.**\n",
    "- $iv.$ For a fixed value of IQ and GPA, females earn more on average than males provided that the GPA is high enough.\n",
    "    \n",
    "### Answer:  \n",
    "- The least square line is given by:\n",
    "$$\\hat{y}=50+20GPA+0.07IQ+35Gender+0.01GPA×IQ−10GPA×Gender$$\n",
    "- For males:\n",
    "$$\\hat{y}=50+20GPA+0.07IQ+0.01GPA×IQ$$\n",
    "- For females:\n",
    "$$\\hat{y}=85+10GPA+0.07IQ+0.01GPA×IQ$$\n",
    "\n",
    "\n",
    "- So the starting salary for females is higher than Males by `$35`, but on average males earn more than females if GPA is higher than 3.5:\n",
    "$$50 + 20GPA \\geq 85 + 10GPA$$\n",
    "$$10GPA \\geq 35$$\n",
    "$$GPA \\geq 3.5$$\n",
    "- **Answer iii. is the correct one**\n",
    "\n",
    "**(b)** Predict the salary of a **female** with **IQ of 110** and a **GPA of 4.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ 137100.0\n"
     ]
    }
   ],
   "source": [
    "gpa, iq, gender = 4, 110, 1\n",
    "\n",
    "ls = 50 + 20*gpa + 0.07*iq + 35*gender + 0.01*gpa*iq + (-10*gpa*gender)\n",
    "print('$', ls * 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$(c)$** **True or false:** Since the coefficient for the $GPA/IQ$ interaction term is very small, there is very little evidence of an interaction effect. Justify your answer.\n",
    "\n",
    "- **False**. the interaction effect might be small but to verify if the $GPA/IQ$ has an impact on the quality of the model we need to test the null hypothesis $H_0:\\hat{\\beta_4}=0$ and look at the **p-value** associated with the $\\text{t-statistic}$ or the $\\text{F-statistic}$ to reject or not reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### $4.$ I collect a set of data (n = 100 observations) containing a single predictor and a quantitative response. I then fit a linear regression model to the data, as well as a separate cubic regression, i.e.  $Y = β_0 + β_1X + β_2X^2 + β_3X^3 + \\epsilon$\n",
    "\n",
    "**$(a)$** Suppose that the true relationship between $X$ and $Y$ is linear, i.e. $Y = β_0 + β_1X + ε$. Consider the training residual sum of squares ($RSS$) for the linear regression, and also the training $RSS$ for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.\n",
    "\n",
    " - Without knowing more details about the training data, it is difficult to know which training $RSS$ is lower between linear or cubic.\n",
    " - However, We would expect the training $RSS$ for the **cubic model to be lower than the linear model** because it is more flexible which allows it to fit more closely variance in the training data despite the true relationship between $X$ and $Y$ is linear.\n",
    " \n",
    " \n",
    "**$(b)$** Answer (a) using test rather than training $RSS$.\n",
    "\n",
    " - We would expect the test $RSS$ for the **linear model to be lower than the cubic model** because The cubic model is more flexible, and so is likely to overfit the training data and would have more error than the linear regression.\n",
    " \n",
    " \n",
    "**$(c)$** Suppose that the true relationship between $X$ and $Y$ is not linear, but we don't know how far it is from linear. Consider the training $RSS$ for the linear regression, and also the training $RSS$ for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.\n",
    "\n",
    " - We would expect the training $RSS$ for the **cubic model to be lower than the linear model** because because of the cubic model flexibility.\n",
    "\n",
    "\n",
    "**$(d)$** Answer (c) using test rather than training RSS.\n",
    "\n",
    " - **There is not enough information to tell.**\n",
    "  - **Cubic would be lower if:**\n",
    "  - The true relationship between $X$ and $Y$ is not linear and there is low noise in our training data.\n",
    "  - **Linear would be lower if:**\n",
    "  - The relationship is only slightly non-linear or the noise in our training data is high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "### $5.$ Consider the fitted values that result from performing linear regression without an intercept. In this setting, the i-th fitted value takes the form:\n",
    "\n",
    "$$\\hat{y_i} = x_i \\hat{\\beta},$$\n",
    "\n",
    "$where$\n",
    "\n",
    "$$\\hat{\\beta} = \\bigg(\\sum_{i=1}^{n}x_i y_i\\bigg) \\bigg/ \\bigg(\\sum_{i'=1}^{n}x_{i'}^2\\bigg)$$\n",
    "\n",
    "Show that we can write\n",
    "\n",
    "$$\\hat{y_i} = \\sum_{i'=1}^n a_{i'} y_{i'}$$\n",
    "\n",
    "What is $a_{i'}$?\n",
    "\n",
    "*Note: We interpret this result by saying that the fitted values from linear regression are linear combinations of the response values.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y_i} = x_i \\frac{\\sum_{i=1}^{n}x_i y_i} {\\sum_{i'=1}^{n} x_{i'}^2}$$\n",
    "\n",
    "$$\\hat{y_i} = \\frac{\\sum_{i'=1}^{n}x_i x_i' }  {\\sum_{i''=1}^{n} x_{i''}^2}y_i$$\n",
    "\n",
    " - $Where$ $$\\hat{y_i} = \\sum_{i'=1}^n a_{i'} y_{i'}$$\n",
    " - $So$ $$a_{i'} = \\frac{x_i x_i' }  {\\sum_{i''=1}^{n} x_{i''}^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "### $6.$ Using $(3.4)$, argue that in the case of simple linear regression, the least squares line always passes through the point $(\\bar{x}, \\bar{y})$.\n",
    "\n",
    "The least square line equation is $\\hat{y}=\\hat{\\beta}_0+\\hat{\\beta}_1 x$, prove that when $x=\\bar{x}$, $\\hat{y} = \\bar{y}$\n",
    "\n",
    "$\\text{When  } x=\\bar{x}$\n",
    "$$\\hat{y}=\\hat{\\beta}_0+\\hat{\\beta}_1 \\bar{x}$$\n",
    "\n",
    "$Where$ $$\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}$$\n",
    "\n",
    "$So$ $$\\hat{y}=\\bar{y} - \\hat{\\beta}_1 \\bar{x}+\\hat{\\beta}_1 x$$\n",
    "\n",
    "$$\\hat{y}=\\bar{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7'></a>\n",
    "### $7.$ It is claimed in the text that in the case of simple linear regression of $Y$ onto $X$, the $R^2$ statistic $(3.17)$ is equal to the square of the correlation between $X$ and $Y$ (3.18). Prove that this is the case. For simplicity, you may assume that $\\bar{x} = \\bar{y}= 0$.\n",
    "\n",
    "\n",
    "**Proposition**: Prove that in case of simple linear regression:\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1 x + \\varepsilon $$\n",
    "\n",
    "the $R^2$ is equal to correlation between $X$ and $Y$ squared, e.g.:\n",
    "\n",
    "$$ R^2 = corr^2(x, y) $$\n",
    "\n",
    "We'll be using the following definitions to prove the above proposition.\n",
    "\n",
    "**Def**:\n",
    "$$ R^2 = 1- \\frac{RSS}{TSS} $$\n",
    "\n",
    "**Def**:\n",
    "$$ RSS = \\sum (y_i - \\hat{y}_i)^2 \\label{RSS} $$ \n",
    "\n",
    "**Def**:\n",
    "$$ TSS = \\sum (y_i - \\bar{y})^2 \\label{TSS} $$\n",
    "\n",
    "**Def**:\n",
    "$$\n",
    "\\begin{align}\n",
    "  corr(x, y) &= \\frac{\\sum (x_i - \\bar{x}) (y_i - \\bar{y})}\n",
    "                     {\\sigma_x \\sigma_y} \\\\\n",
    "  \\sigma_x^2 &= \\sum (x_i - \\bar{x})^2 \\\\\n",
    "  \\sigma_y^2 &= \\sum (y_i - \\bar{y})^2\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof**:\n",
    "\n",
    "Substitute defintions of TSS and RSS into $R^2$:\n",
    "\n",
    "$$\n",
    "R^2 = 1-\\frac{\\sum (y_i - \\hat{y}_i)^2}\n",
    "           {\\sum y_i^2}\n",
    "$$\n",
    "\n",
    "\n",
    "Recall that:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "  \\hat{\\beta}_0 &= \\bar{y} - \\hat{\\beta}_1 \\bar{x} \\label{beta0} \\\\\n",
    "  \\hat{\\beta}_1 &= \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}\n",
    "                        {\\sum (x_i - \\bar{x})^2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Substitute the expression for $\\hat{\\beta}_0$ into $\\hat{y}_i$:\n",
    "And with $\\bar{x} = \\bar{y} = 0$\n",
    "$$\n",
    "\\begin{align}\n",
    "  \\hat{y}_i &= \\hat{\\beta}_1 x_i \\\\\n",
    "  \\hat{y}_i &= \\frac{\\sum x_i y_i}\n",
    "                        {\\sum x_i^2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$Then$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "        R^2 &= 1-\\frac{\\sum (y_i - \\frac{\\sum x_i y_i}\n",
    "                                    {\\sum x_i^2})^2}\n",
    "                  {\\sum y_i^2}\\\\\n",
    "            &= \\frac{\\sum{y_i^2} -2\\sum y_i (\\frac{\\sum x_i y_i}\n",
    "                     {\\sum x_i^2})x_i+\\sum(\\frac{\\sum x_i y_i}\n",
    "                                                {\\sum x_i^2})^2 x_i^2)}\n",
    "                {\\sum y_i^2}\\\\\n",
    "            &= \\frac{\\frac{2(\\sum x_i y_i)^2}{\\sum x_i^2} - \\frac{(\\sum x_i y_i)^2}{\\sum x_i^2}}{\\sum y_i^2}\\\\\n",
    "            &= \\frac{(\\sum x_i y_i)^2}{\\sum x_i^2 \\sum y_i^2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$ \\text{with } \\bar{x} = \\bar{y} = 0$\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "  corr(x, y) &= \\frac{\\sum x_i y_i}\n",
    "                     {\\sum x_i^2 \\sum y_i^2} = R^2\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
